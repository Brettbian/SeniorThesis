Deep learning is driving advances in the machine learning field by implementing various kinds of neural networks inspired by the architecture of human brains. Generative models are a specific branch of deep learning, which is an unsupervised model that can be applied to artistic style transfer, image synthesis, image-to-image translation, etc. \cite{IEEE_intro}\cite{reed2016generative}\cite{li2016precomputed}. For example, a trained model can generate several credible images based on a text description \cite{reed2016learning}. Despite the empirical success of the algorithm of generative adversarial networks (GANs) \cite{goodfellow2014generative}, the neural networks are often viewed as a black box. In other words, it is hard to know what each layer or each neuron does. To increase the explain-ability, Weinan E et al. \cite{weinan2018mean} has connected the modeling and analysis of the residual neural networks (resNet) learning problem \cite{he2016deep} with the mean field control theory \cite{bensoussan2013mean} in order to provide insights into the role of hidden layers within a rigorous mathematical framework. In this thesis, we will examine GANs composed by two resNet following the same framework to theorize, visualize and the effect of each layer, and hence better understand the black box. The thesis is organized as the following. In Chapter \ref{chp-Background}, we first introduce the idea of GANs and resNet. Then we begin with the classical optimal control theory and extend it to mean field dynamical systems. Especially, we state two fundamental theorems in optimal control: Hamilton–Jacobi–Bellman equation and Pontryagin Maximum Principle. In Chapter \ref{chp-formulation}, we specify a mathematical formulation of the GAN with 2 resNet problem in terms of a mean field dynamical system. In Chapter \ref{chp-Experiments and Visualization}, we conduct experiments on the learning of simple distributions and visualize the dynamical process of both the resNet generator and the resNet discriminator to visualize and give insights into what each layer does. Finally, in Chapter \ref{chp-conclusion}, we present the conclusion and further discussion of the problem.